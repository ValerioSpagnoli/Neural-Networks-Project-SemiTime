{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Project\n",
    "### Reimplementation of SemiTime\n",
    "\n",
    "Course: Master in Artificial Intelligence and Robotics 2022-2023\n",
    "\n",
    "Student: Spagnoli Valerio 1887715\n",
    "\n",
    "Paper: **Semi-supervised time series classification by temporal relation prediction** (https://haoyfan.github.io/papers/SemiTime_ICASSP2021.pdf)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriprion of SemiTime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Idea\n",
    "\n",
    "This project is based on the paper \"Semi-supervised time series classification by temporal relation prediction\", which describes a novel approach for time series classification.\n",
    "In this work the authors have proposed a method of semi-supervised time series classification architecture (termed as **SemiTime**) by gaining from the structure of unlabeled data in a self-supervised manner. \n",
    "\n",
    "The main idea of SemiTime is to use the labelled data of dataset for a classic supervised classification, and unlabelled data of dataset for a self-superviesed temporal relation classification. \\\n",
    "The temporal relation classification is used to help the model in features extracting phase."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "There are two models:  \n",
    "- backbone encoder $ f_{\\theta} $ + classification head $ h_{\\mu} $\n",
    "- backbone encoder $ f_{\\theta} $ + relation head $ h_{\\phi} $\n",
    "\n",
    "The backbone encoder is the same for both of models, and is a 4-layer 1D convolutional neural network with ReLU activation function and batch normalization.\n",
    "\n",
    "The classification head is linear layer with output = number of classes of dataset.\n",
    "\n",
    "The relation head is a two layer fully connected networks with 256 hidden neurons.\n",
    "\n",
    "**Supervised classification of classes**:\n",
    "\n",
    "The first model perform a supervised classification of classes: given the labelled dataset $ \\mathcal{D}_L = \\{(\\bold{t}_i, y_i)\\}_{i=0}^M $, the backbone encoder $ f_{\\theta} $ takes the time series as input to extract the feature embedding $ \\mathcal{z}_i = f_{\\theta}(\\bold{t}_i) $, and then the classification head $ h_{\\mu} $ perfoms the multiclass classification. \\\n",
    "For this part is used the Cross Entropy loss.\n",
    "\n",
    "**Self-supervised classification of temporal relation**:\n",
    "\n",
    "The second model perform a self-supervised classification of temporal relation between two segments. \\\n",
    "Given two segments, if the second is the future segmens of the first, they are in positive relation (labelled with 1), otherwise they are in negative relation (labelled with 0). \\\n",
    "So, given the unlabelled dataset  $ \\mathcal{D}_U = \\{(\\bold{t}_i)\\}_{i=0}^N $, each time series is split in two parts:\n",
    "- the first part denotes the past segments,\n",
    "- the second part denotes the future segmens.\n",
    "\n",
    "\n",
    "For each segment in $ \\mathcal{D}_U $ are created 2 segments (both of them split in 2 parts):\n",
    "- the first is composed by the past and future parts of the same segmets, i.e. $ \\bold{s}_i $ and $ \\bold{s}_i^+ $ , and represents the positive relation (label = 1);\n",
    "- the second is composed by the same past segment of the first one, i.e. $ \\bold{s}_i $, but with a different future segment taken form another sample in $ \\mathcal{D}_U $, i.e. $ \\bold{s}_j^- $. This segment represents the negative relation (label = 0);\n",
    "\n",
    "The backbone encoder takes for each segment $ \\bold{s}_i $, $ \\bold{s}_i^+ $ and $ \\bold{s}_i^- $ to extract the features embedding $ \\mathcal{z}_i = f_{\\theta} (\\bold{s}_i) $, $ \\mathcal{z}_i^+ = f_{\\theta} (\\bold{s}_i^+) $ and $ \\mathcal{z}_i^- = f_{\\theta} (\\bold{s}_i)^- $, and then the relation head $ h_{\\phi} $ perform temporal relation prediction between segments (binary classification problem):\n",
    "- $ h_{\\phi} = ([\\mathcal{z}_i, \\mathcal{z}_i^+ ])$ for positive relation;\n",
    "- $ h_{\\phi} = ([\\mathcal{z}_i, \\mathcal{z}_i^- ])$ for negative relation;\n",
    "For this part is used the Binary Cross Entropy loss\n",
    "\n",
    "Note: $[\\cdot, \\cdot ]$ is the concatenation operation.\n",
    "\n",
    "\n",
    "|Schematic illustration of semi-supervised techniques described| SemiTime architecture|\n",
    "|--------|--------|\n",
    "|  ![schematic_illustration](../images/schematic_illustration.png)  |  ![SemiTime_architecture](../images/SemiTime_architecture.png)  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Note: \n",
    "- the $\\mathcal{D}_L$ dataset is contained in $\\mathcal{D}_U $ and can be maximum equal to $\\mathcal{D_U} $ (i.e. $ M \\le N$).\n",
    "- for supervised classificaiton part is used only $\\mathcal{D}_L$\n",
    "- for self-supervised classificaiton part is used the entire dataset $ \\mathcal{D}_U $, also the labelled data (without taking the label).\n",
    "\n",
    "For this project are used the following dataset:\n",
    "- CricketX, UWaveGestureLibraryAll, InsectWingbeatSound: http://www.timeseriesclassification.com/dataset.php \n",
    "- XJTU bearing dataset: https://biaowang.tech/xjtu-sy-bearing-datasets/ \n",
    "- MFPT fault dataset: https://www.mfpt.org/fault-data-sets/ \n",
    "- Epilectic Seizure Recognitions: https://archive-beta.ics.uci.edu/dataset/388/epileptic+seizure+recognition \n",
    "  \n",
    "and is used always the entire dataset both for supervised and semi-supervised tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import get_dataset, supervised, semi_supervised, test_model\n",
    "from settings import globalSettings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With module globalSetting you can create a 'setter' with all the necessary settings.\n",
    "- dataset: name of dataset\n",
    "- num_folds: number of fold of K-Fold Cross Validations\n",
    "- batch_size: number of samples in one batch\n",
    "- num_features: number of features returned from backbone\n",
    "- learning_rate: learning rate of Adam optimizer\n",
    "- patience: number of epochs without stopping where loss > minimum recordered loss on current fold\n",
    "- device: can be 'cpu', 'cuda', 'mps', depending on the available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setter = globalSettings.GlobalSettings(dataset='CricketX', \n",
    "                                        num_folds=8, \n",
    "                                        num_epochs=1000, \n",
    "                                        batch_size=128, \n",
    "                                        num_features=64, \n",
    "                                        learning_rate=0.01, \n",
    "                                        patience=200,\n",
    "                                        device='mps') # choose here the device ('cpu', 'cuda', 'mps')\n",
    "\n",
    "\n",
    "dataset_name = setter.__get_settings__(variable='dataset')\n",
    "num_features = setter.__get_settings__(variable='num_features')\n",
    "learning_rate = setter.__get_settings__(variable='learning_rate')\n",
    "split_ratio = setter.__get_settings__(variable='split_ratio')\n",
    "device = setter.__get_settings__(variable='device')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the labelled dataset $\\mathcal{D}_L$, the unlabelled dataset $\\mathcal{D}_U$ (already splitted in past and future segments), the test dataset and the number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelledDataset, unlabelledDataset, testDataset, num_classes = get_dataset(dataset_name=dataset_name, split_ratio=split_ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: the 'save' parameter is set to False. If you set this parameter to 'True' and run the cell, all previous checkpoints on the loaded dataset are automatically lost.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised(labelledDataset=labelledDataset, num_classes=num_classes, num_features=num_features, learning_rate=learning_rate, \n",
    "           device=device, setter=setter, save=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semi-Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_supervised(labelledDataset=labelledDataset, unlabelledDataset=unlabelledDataset, num_classes=num_classes, num_features=num_features, \n",
    "                learning_rate=learning_rate, device=device, setter=setter, save=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs the test on the model saved in './checkpoint/< task >/< dataset_name >'.\n",
    "\n",
    "Note: the parameter 'task' can be 'supervised' or 'semi-supervised'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(task='supervised', dataset_name=dataset_name, dataset=testDataset, num_classes=num_classes, num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(task='semi-supervised', dataset_name=dataset_name, dataset=testDataset, num_classes=num_classes, num_features=num_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results published in the paper\n",
    "![schematic_illustration](../images/results_paper.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of supervised model on dataset CricketX\n",
      "Loss: 2.166\n",
      "Accuracy: 40.256%\n",
      "\n",
      "Test of semi-supervised model on dataset CricketX\n",
      "Loss: 1.861\n",
      "Accuracy: 44.103%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_, CricketX_test, num_classes_CricketX = get_dataset(dataset_name='CricketX', split_ratio=split_ratio)\n",
    "test_model(task='supervised', dataset_name='CricketX', dataset=CricketX_test, num_classes=num_classes_CricketX, num_features=num_features)\n",
    "test_model(task='semi-supervised', dataset_name='CricketX', dataset=CricketX_test, num_classes=num_classes_CricketX, num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of supervised model on dataset UWaveGestureLibraryAll\n",
      "Loss: 1.333\n",
      "Accuracy: 58.096%\n",
      "\n",
      "Test of semi-supervised model on dataset UWaveGestureLibraryAll\n",
      "Loss: 1.216\n",
      "Accuracy: 57.677%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_, UWaveGestureLibraryAll_test, num_classes_UWaveGestureLibraryAll = get_dataset(dataset_name='UWaveGestureLibraryAll', split_ratio=split_ratio)\n",
    "test_model(task='supervised', dataset_name='UWaveGestureLibraryAll', dataset=UWaveGestureLibraryAll_test, num_classes=num_classes_UWaveGestureLibraryAll, num_features=num_features)\n",
    "test_model(task='semi-supervised', dataset_name='UWaveGestureLibraryAll', dataset=UWaveGestureLibraryAll_test, num_classes=num_classes_UWaveGestureLibraryAll, num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of supervised model on dataset InsectWingbeatSound\n",
      "Loss: 2.160\n",
      "Accuracy: 32.273%\n",
      "\n",
      "Test of semi-supervised model on dataset InsectWingbeatSound\n",
      "Loss: 1.946\n",
      "Accuracy: 31.111%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_, InsectWingbeatSound_test, num_classes_InsectWingbeatSound = get_dataset(dataset_name='InsectWingbeatSound', split_ratio=split_ratio)\n",
    "test_model(task='supervised', dataset_name='InsectWingbeatSound', dataset=InsectWingbeatSound_test, num_classes=num_classes_InsectWingbeatSound, num_features=num_features)\n",
    "test_model(task='semi-supervised', dataset_name='InsectWingbeatSound', dataset=InsectWingbeatSound_test, num_classes=num_classes_InsectWingbeatSound, num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of supervised model on dataset MFPT\n",
      "Loss: 1.392\n",
      "Accuracy: 53.768%\n",
      "\n",
      "Test of semi-supervised model on dataset MFPT\n",
      "Loss: 1.478\n",
      "Accuracy: 49.961%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_, MFPT_test, num_classes_MFPT = get_dataset(dataset_name='MFPT', split_ratio=split_ratio)\n",
    "test_model(task='supervised', dataset_name='MFPT', dataset=MFPT_test, num_classes=num_classes_MFPT, num_features=num_features)\n",
    "test_model(task='semi-supervised', dataset_name='MFPT', dataset=MFPT_test, num_classes=num_classes_MFPT, num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of supervised model on dataset XJTU\n",
      "Loss: 0.918\n",
      "Accuracy: 68.854%\n",
      "\n",
      "Test of semi-supervised model on dataset XJTU\n",
      "Loss: 1.187\n",
      "Accuracy: 59.167%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_, XJTU_test, num_classes_XJTU = get_dataset(dataset_name='XJTU', split_ratio=split_ratio)\n",
    "test_model(task='supervised', dataset_name='XJTU', dataset=XJTU_test, num_classes=num_classes_XJTU, num_features=num_features)\n",
    "test_model(task='semi-supervised', dataset_name='XJTU', dataset=XJTU_test, num_classes=num_classes_XJTU, num_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_, EpilepticSeizure_test, num_classes_EpilepticSeizure = get_dataset(dataset_name='EpilepticSeizure', split_ratio=split_ratio)\n",
    "test_model(task='supervised', dataset_name='EpilepticSeizure', dataset=EpilepticSeizure_test, num_classes=num_classes_EpilepticSeizure, num_features=num_features)\n",
    "test_model(task='semi-supervised', dataset_name='EpilepticSeizure', dataset=EpilepticSeizure_test, num_classes=num_classes_EpilepticSeizure, num_features=num_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
